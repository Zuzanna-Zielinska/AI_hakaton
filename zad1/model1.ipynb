{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from taskdataset import TaskDataset\n",
    "import torchvision\n",
    "import cv2\n",
    "\n",
    "path_to_data = \"datasets/ModelStealingPub.pt\" # TODO Set path to datasets files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gray:  13000\n",
      "RGB:  0\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.load(path_to_data)\n",
    "\n",
    "ids = []\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "ids_gray = []\n",
    "imgs_gray = []\n",
    "labels_gray = []\n",
    "\n",
    "gray = 0\n",
    "rgb = 0\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    el = [dataset.ids[i], np.array(dataset.imgs[i]), int(dataset.labels[i])]\n",
    "\n",
    "    # if el[1].shape != (32, 32, 3):\n",
    "    #     rgb += 1\n",
    "    #     ids.append(el[0])\n",
    "    #     imgs.append(el[1])\n",
    "    #     labels.append(el[2])        \n",
    "    # else:\n",
    "    #     gray += 1\n",
    "    #     ids_gray.append(el[0])\n",
    "    #     imgs_gray.append(el[1])\n",
    "    #     labels_gray.append(el[2])\n",
    "    if el[1].shape != (32, 32, 3):\n",
    "        #convert to RGB\n",
    "        el[1] = cv2.cvtColor(el[1], cv2.COLOR_GRAY2RGB)\n",
    "        #convert to tensor\n",
    "        dataset.imgs[i] = torch.from_numpy(el[1])\n",
    "    else:\n",
    "        #convert to tensor\n",
    "        dataset.imgs[i] = torch.from_numpy(el[1])\n",
    "    \n",
    "\n",
    "    if el[1].shape != (32, 32, 3):\n",
    "        rgb += 1\n",
    "        # ids.append(el[0])\n",
    "        # imgs.append(el[1])\n",
    "        # labels.append(el[2])        \n",
    "    else:\n",
    "        gray += 1\n",
    "        # ids_gray.append(el[0])\n",
    "        # imgs_gray.append(el[1])\n",
    "        # labels_gray.append(el[2])\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "print(\"Gray: \", gray)\n",
    "print(\"RGB: \", rgb)\n",
    "\n",
    "\n",
    "# create dataset\n",
    "# imgs = TaskDataset(imgs, transform)\n",
    "# imgs_gray = TaskDataset([ids_gray, imgs_gray, labels_gray], transform)\n",
    "\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset = dataset.imgs,\n",
    "                                     batch_size = 32,\n",
    "                                     shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180360"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for data in iter(dataset):\n",
    "#     print(data)\n",
    "\n",
    "# plt.imshow(dataset[0])\n",
    "plt.imshow(dataset[10][1])\n",
    "dataset[10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 32, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(loader)\n",
    "next(dataiter).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(dataset.imgs[0])\n",
    "print(a.shape)\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Transforms images to a PyTorch Tensor\n",
    "# tensor_transform = transforms.ToTensor()\n",
    " \n",
    "# # Download the MNIST Dataset\n",
    "# dataset = datasets.MNIST(root = \"./data\",\n",
    "#                          train = True,\n",
    "#                          download = True,\n",
    "#                          transform = tensor_transform)\n",
    " \n",
    "# # DataLoader is used to load the dataset \n",
    "# # for training\n",
    "# loader = torch.utils.data.DataLoader(dataset = dataset,\n",
    "#                                      batch_size = 32,\n",
    "#                                      shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a PyTorch class\n",
    "# 28*28 ==> 9 ==> 28*28\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "         \n",
    "        # Building an linear encoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # 784 ==> 9\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3 * 32 * 32, 1536),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1536, 1536),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1536, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 18),\n",
    "        )\n",
    "         \n",
    " \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     18\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, _ \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     20\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m)  \u001b[38;5;66;03m# Przekształcenie danych do odpowiednich wymiarów\u001b[39;00m\n\u001b[0;32m     21\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# # Wczytanie danych\n",
    "# path_to_data = \"datasets/ModelStealingPub.pt\"\n",
    "# data = torch.load(path_to_data)\n",
    "\n",
    "# # Przygotowanie danych treningowych (załóżmy, że dane są już gotowe w odpowiednim formacie)\n",
    "# train_loader = torch.utils.data.DataLoader(data, batch_size=64, shuffle=True)\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = AE()\n",
    "\n",
    "# Definicja funkcji straty i optymalizatora\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Trening modelu\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, _ in loader:\n",
    "        inputs = inputs.view(-1, 3 * 32 * 32)  # Przekształcenie danych do odpowiednich wymiarów\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)  # Porównujemy wyjście modelu z danymi wejściowymi\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(loader)}\")\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "model = AE()\n",
    " \n",
    "# Validation using MSE Loss function\n",
    "loss_function = torch.nn.MSELoss()\n",
    " \n",
    "# Using an Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-1,\n",
    "                             weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (image, _) \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m      6\u001b[0m        \n\u001b[0;32m      7\u001b[0m       \u001b[38;5;66;03m# Reshaping the image to (-1, 784)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m       image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\n\u001b[0;32m     10\u001b[0m       \u001b[38;5;66;03m# Output of Autoencoder\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "outputs = []\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    for (image, _) in loader:\n",
    "       \n",
    "      # Reshaping the image to (-1, 784)\n",
    "      image = image.reshape(-1, 28*28)\n",
    "       \n",
    "      # Output of Autoencoder\n",
    "      reconstructed = model(image)\n",
    "       \n",
    "      # Calculating the loss function\n",
    "      loss = loss_function(reconstructed, image)\n",
    "       \n",
    "      # The gradients are set to zero,\n",
    "      # the gradient is computed and stored.\n",
    "      # .step() performs parameter update\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "       \n",
    "      # Storing the losses in a list for plotting\n",
    "      losses.append(loss)\n",
    "    outputs.append((epochs, image, reconstructed))\n",
    " \n",
    "# Defining the Plot Style\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Plotting the last 100 values\n",
    "plt.plot(losses[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
