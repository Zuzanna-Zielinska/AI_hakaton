{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data_file=np.load(\"DefenseTransformationEvaluate.npz\")\n",
    "labels=data_file['labels']\n",
    "x=data_file['representations']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return x[indices], y[indices]\n",
    "\n",
    "def split_data(x, y, ratio=0.8):\n",
    "    x, y = shuffle(x, y)\n",
    "    split = int(x.shape[0] * ratio)\n",
    "    x_train, y_train = x[:split], y[:split]\n",
    "    x_test, y_test = x[split:], y[split:]\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x,y=shuffle(x,labels)\n",
    "x_train, y_train = x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    net = Sequential()\n",
    "    net.add(Dense(2048, activation='relu'))\n",
    "    net.add(Dropout(0.7))\n",
    "    net.add(Dense(1024, activation='relu'))\n",
    "    net.add(Dropout(0.7))\n",
    "    net.add(Dense(512, activation='relu'))\n",
    "    net.add(Dropout(0.6))\n",
    "    net.add(Dense(256, activation='relu'))\n",
    "    net.add(Dropout(0.4))\n",
    "    net.add(Dense(128, activation='relu'))\n",
    "    net.add(Dropout(0.5))\n",
    "    net.add(Dense(64, activation='relu'))\n",
    "    net.add(Dropout(0.5))\n",
    "    net.add(Dense(10, activation='softmax'))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = create_model()\n",
    "net.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 4.3181 - accuracy: 0.1167 - val_loss: 2.2909 - val_accuracy: 0.2090\n",
      "Epoch 2/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 2.3979 - accuracy: 0.1168 - val_loss: 2.1874 - val_accuracy: 0.2480\n",
      "Epoch 3/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 2.2288 - accuracy: 0.1633 - val_loss: 1.7065 - val_accuracy: 0.4510\n",
      "Epoch 4/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.9232 - accuracy: 0.2282 - val_loss: 1.3454 - val_accuracy: 0.4990\n",
      "Epoch 5/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.6273 - accuracy: 0.3337 - val_loss: 1.1225 - val_accuracy: 0.6700\n",
      "Epoch 6/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.3807 - accuracy: 0.4276 - val_loss: 0.8570 - val_accuracy: 0.7100\n",
      "Epoch 7/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 1.2208 - accuracy: 0.5244 - val_loss: 0.6637 - val_accuracy: 0.7240\n",
      "Epoch 8/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.0178 - accuracy: 0.5990 - val_loss: 0.5989 - val_accuracy: 0.8220\n",
      "Epoch 9/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.9078 - accuracy: 0.6693 - val_loss: 0.4803 - val_accuracy: 0.8590\n",
      "Epoch 10/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.8738 - accuracy: 0.7141 - val_loss: 0.4693 - val_accuracy: 0.8540\n",
      "Epoch 11/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.8172 - accuracy: 0.7204 - val_loss: 0.4590 - val_accuracy: 0.8970\n",
      "Epoch 12/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6865 - accuracy: 0.7632 - val_loss: 0.4179 - val_accuracy: 0.9070\n",
      "Epoch 13/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.7021 - accuracy: 0.7689 - val_loss: 0.3571 - val_accuracy: 0.9170\n",
      "Epoch 14/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6604 - accuracy: 0.7862 - val_loss: 0.3721 - val_accuracy: 0.9150\n",
      "Epoch 15/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5937 - accuracy: 0.8096 - val_loss: 0.4346 - val_accuracy: 0.8870\n",
      "Epoch 16/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6312 - accuracy: 0.7985 - val_loss: 0.4048 - val_accuracy: 0.9270\n",
      "Epoch 17/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5919 - accuracy: 0.8403 - val_loss: 0.4462 - val_accuracy: 0.9180\n",
      "Epoch 18/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6523 - accuracy: 0.8225 - val_loss: 0.4266 - val_accuracy: 0.9330\n",
      "Epoch 19/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5647 - accuracy: 0.8398 - val_loss: 0.5031 - val_accuracy: 0.9170\n",
      "Epoch 20/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5653 - accuracy: 0.8376 - val_loss: 0.3362 - val_accuracy: 0.9230\n",
      "Epoch 21/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4994 - accuracy: 0.8406 - val_loss: 0.3771 - val_accuracy: 0.9300\n",
      "Epoch 22/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5490 - accuracy: 0.8473 - val_loss: 0.3504 - val_accuracy: 0.9350\n",
      "Epoch 23/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4891 - accuracy: 0.8614 - val_loss: 0.3001 - val_accuracy: 0.9400\n",
      "Epoch 24/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5702 - accuracy: 0.8620 - val_loss: 0.2908 - val_accuracy: 0.9370\n",
      "Epoch 25/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4817 - accuracy: 0.8607 - val_loss: 0.2927 - val_accuracy: 0.9450\n",
      "Epoch 26/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4485 - accuracy: 0.8790 - val_loss: 0.2923 - val_accuracy: 0.9420\n",
      "Epoch 27/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.8639 - val_loss: 0.3122 - val_accuracy: 0.9450\n",
      "Epoch 28/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4631 - accuracy: 0.8785 - val_loss: 0.3043 - val_accuracy: 0.9480\n",
      "Epoch 29/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4108 - accuracy: 0.8845 - val_loss: 0.3786 - val_accuracy: 0.9450\n",
      "Epoch 30/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3879 - accuracy: 0.9099 - val_loss: 0.3022 - val_accuracy: 0.9490\n",
      "Epoch 31/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4478 - accuracy: 0.8920 - val_loss: 0.3569 - val_accuracy: 0.9420\n",
      "Epoch 32/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4980 - accuracy: 0.8905 - val_loss: 0.3322 - val_accuracy: 0.9460\n",
      "Epoch 33/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4249 - accuracy: 0.8968 - val_loss: 0.2395 - val_accuracy: 0.9500\n",
      "Epoch 34/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3844 - accuracy: 0.9131 - val_loss: 0.3145 - val_accuracy: 0.9530\n",
      "Epoch 35/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3845 - accuracy: 0.8920 - val_loss: 0.3143 - val_accuracy: 0.9440\n",
      "Epoch 36/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4808 - accuracy: 0.8950 - val_loss: 0.2746 - val_accuracy: 0.9500\n",
      "Epoch 37/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4107 - accuracy: 0.8906 - val_loss: 0.2743 - val_accuracy: 0.9550\n",
      "Epoch 38/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4083 - accuracy: 0.9017 - val_loss: 0.2545 - val_accuracy: 0.9560\n",
      "Epoch 39/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4319 - accuracy: 0.9013 - val_loss: 0.2422 - val_accuracy: 0.9590\n",
      "Epoch 40/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4642 - accuracy: 0.8916 - val_loss: 0.2253 - val_accuracy: 0.9530\n",
      "Epoch 41/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3477 - accuracy: 0.9155 - val_loss: 0.2059 - val_accuracy: 0.9530\n",
      "Epoch 42/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3991 - accuracy: 0.8997 - val_loss: 0.2597 - val_accuracy: 0.9510\n",
      "Epoch 43/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4163 - accuracy: 0.9180 - val_loss: 0.2769 - val_accuracy: 0.9600\n",
      "Epoch 44/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4874 - accuracy: 0.9065 - val_loss: 0.2869 - val_accuracy: 0.9580\n",
      "Epoch 45/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2801 - accuracy: 0.9226 - val_loss: 0.2898 - val_accuracy: 0.9550\n",
      "Epoch 46/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3230 - accuracy: 0.9247 - val_loss: 0.3262 - val_accuracy: 0.9560\n",
      "Epoch 47/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4129 - accuracy: 0.9194 - val_loss: 0.2258 - val_accuracy: 0.9580\n",
      "Epoch 48/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3647 - accuracy: 0.9155 - val_loss: 0.2456 - val_accuracy: 0.9600\n",
      "Epoch 49/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3685 - accuracy: 0.9093 - val_loss: 0.2455 - val_accuracy: 0.9610\n",
      "Epoch 50/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.9150 - val_loss: 0.2635 - val_accuracy: 0.9580\n",
      "Epoch 51/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3559 - accuracy: 0.9187 - val_loss: 0.2295 - val_accuracy: 0.9610\n",
      "Epoch 52/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3555 - accuracy: 0.9158 - val_loss: 0.2662 - val_accuracy: 0.9570\n",
      "Epoch 53/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3943 - accuracy: 0.9149 - val_loss: 0.2856 - val_accuracy: 0.9560\n",
      "Epoch 54/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4520 - accuracy: 0.9162 - val_loss: 0.2329 - val_accuracy: 0.9550\n",
      "Epoch 55/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3013 - accuracy: 0.9339 - val_loss: 0.3253 - val_accuracy: 0.9530\n",
      "Epoch 56/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3121 - accuracy: 0.9221 - val_loss: 0.2774 - val_accuracy: 0.9620\n",
      "Epoch 57/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2904 - accuracy: 0.9310 - val_loss: 0.2381 - val_accuracy: 0.9600\n",
      "Epoch 58/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3992 - accuracy: 0.9144 - val_loss: 0.2362 - val_accuracy: 0.9570\n",
      "Epoch 59/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3174 - accuracy: 0.9206 - val_loss: 0.2942 - val_accuracy: 0.9480\n",
      "Epoch 60/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3870 - accuracy: 0.9201 - val_loss: 0.2581 - val_accuracy: 0.9560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc21e620070>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(x_train, y_train, epochs=60, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save('classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinic_transform(x):\n",
    "    #22_proba1.pnz\n",
    "    array_size = x.shape\n",
    "    mul = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    add = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    matrix_mult = np.tile(mul,(array_size[0],1))\n",
    "    matrix_add = np.tile(add,(array_size[0],1))\n",
    "    return np.multiply(x,matrix_mult)+matrix_add,mul,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinic_transform2(x):\n",
    "    #22_proba1.pnz\n",
    "    array_size = x.shape\n",
    "    mul = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    add = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    matrix_mult = np.tile(mul,(array_size[0],1))\n",
    "    matrix_add = np.tile(add,(array_size[0],1))\n",
    "    result = np.multiply(x,matrix_mult)+matrix_add\n",
    "    \n",
    "    return result,mul,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transform, mul, add = affinic_transform2(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_aff = create_model()\n",
    "\n",
    "net_aff.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 3.2046 - accuracy: 0.1020 - val_loss: 2.2626 - val_accuracy: 0.2050\n",
      "Epoch 2/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 2.2941 - accuracy: 0.1342 - val_loss: 1.8976 - val_accuracy: 0.2880\n",
      "Epoch 3/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.9719 - accuracy: 0.2270 - val_loss: 1.3775 - val_accuracy: 0.4360\n",
      "Epoch 4/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.6116 - accuracy: 0.3548 - val_loss: 1.0040 - val_accuracy: 0.6290\n",
      "Epoch 5/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.2981 - accuracy: 0.4535 - val_loss: 0.7844 - val_accuracy: 0.6420\n",
      "Epoch 6/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.1613 - accuracy: 0.5354 - val_loss: 0.6909 - val_accuracy: 0.7490\n",
      "Epoch 7/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 1.0331 - accuracy: 0.5719 - val_loss: 0.6430 - val_accuracy: 0.7550\n",
      "Epoch 8/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.9273 - accuracy: 0.6202 - val_loss: 0.5953 - val_accuracy: 0.7780\n",
      "Epoch 9/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.8835 - accuracy: 0.6644 - val_loss: 0.5757 - val_accuracy: 0.7700\n",
      "Epoch 10/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.7866 - accuracy: 0.6908 - val_loss: 0.5475 - val_accuracy: 0.8330\n",
      "Epoch 11/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.7418 - accuracy: 0.7245 - val_loss: 0.5013 - val_accuracy: 0.8300\n",
      "Epoch 12/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.7171 - accuracy: 0.7212 - val_loss: 0.5283 - val_accuracy: 0.8330\n",
      "Epoch 13/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6938 - accuracy: 0.7460 - val_loss: 0.5115 - val_accuracy: 0.8010\n",
      "Epoch 14/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.7501 - val_loss: 0.5958 - val_accuracy: 0.7890\n",
      "Epoch 15/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6436 - accuracy: 0.7758 - val_loss: 0.4900 - val_accuracy: 0.8590\n",
      "Epoch 16/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6119 - accuracy: 0.7848 - val_loss: 0.5112 - val_accuracy: 0.8560\n",
      "Epoch 17/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.6268 - accuracy: 0.7943 - val_loss: 0.4674 - val_accuracy: 0.8720\n",
      "Epoch 18/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6332 - accuracy: 0.7733 - val_loss: 0.3534 - val_accuracy: 0.8890\n",
      "Epoch 19/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5716 - accuracy: 0.8033 - val_loss: 0.4355 - val_accuracy: 0.8650\n",
      "Epoch 20/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.8068 - val_loss: 0.3938 - val_accuracy: 0.9040\n",
      "Epoch 21/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5576 - accuracy: 0.8139 - val_loss: 0.3636 - val_accuracy: 0.9200\n",
      "Epoch 22/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5911 - accuracy: 0.8308 - val_loss: 0.3587 - val_accuracy: 0.9100\n",
      "Epoch 23/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.8351 - val_loss: 0.3840 - val_accuracy: 0.9180\n",
      "Epoch 24/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5525 - accuracy: 0.8323 - val_loss: 0.3797 - val_accuracy: 0.9130\n",
      "Epoch 25/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.8572 - val_loss: 0.3420 - val_accuracy: 0.9300\n",
      "Epoch 26/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4635 - accuracy: 0.8669 - val_loss: 0.3746 - val_accuracy: 0.9250\n",
      "Epoch 27/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.5262 - accuracy: 0.8750 - val_loss: 0.3285 - val_accuracy: 0.9270\n",
      "Epoch 28/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4326 - accuracy: 0.8858 - val_loss: 0.2870 - val_accuracy: 0.9320\n",
      "Epoch 29/60\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8897 - val_loss: 0.3219 - val_accuracy: 0.9280\n",
      "Epoch 30/60\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.8764 - val_loss: 0.3270 - val_accuracy: 0.9250\n",
      "Epoch 31/60\n",
      "174/250 [===================>..........] - ETA: 0s - loss: 0.3732 - accuracy: 0.9065"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnet_aff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DNN/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/DNN/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/anaconda3/envs/DNN/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    853\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    858\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/DNN/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DNN/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/DNN/lib/python3.8/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/DNN/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net_aff.fit(x_transform, y_train, epochs=60, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load(\"DefenseTransformationSubmit.npz\")\n",
    "X_EVAL=X['representations']\n",
    "X_EVAL,_,_ = affinic_transform(X_EVAL)\n",
    "X_EVAL = X_EVAL.astype('float32')\n",
    "np.savez(\"23_proba2.npz\",representations=X_EVAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['representations']\n",
      "(20250, 192)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "b=np.load(\"23_proba2.npz\",allow_pickle=True)\n",
    "X_EVAL=b['representations']\n",
    "print(b.files)\n",
    "print(X_EVAL.shape)\n",
    "print(X_EVAL[0].dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
