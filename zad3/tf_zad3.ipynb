{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data_file=np.load(\"/home/mati/AGH/AIHack/DefenseTransformationEvaluate.npz\")\n",
    "labels=data_file['labels']\n",
    "x=data_file['representations']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return x[indices], y[indices]\n",
    "\n",
    "def split_data(x, y, ratio=0.8):\n",
    "    x, y = shuffle(x, y)\n",
    "    split = int(x.shape[0] * ratio)\n",
    "    x_train, y_train = x[:split], y[:split]\n",
    "    x_test, y_test = x[split:], y[split:]\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x,y=shuffle(x,labels)\n",
    "x_train, y_train = x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    net = Sequential()\n",
    "    net.add(Dense(2048, activation='relu'))\n",
    "    net.add(Dropout(0.7))\n",
    "    net.add(Dense(1024, activation='relu'))\n",
    "    net.add(Dropout(0.7))\n",
    "    net.add(Dense(512, activation='relu'))\n",
    "    net.add(Dropout(0.6))\n",
    "    net.add(Dense(256, activation='relu'))\n",
    "    net.add(Dropout(0.4))\n",
    "    net.add(Dense(128, activation='relu'))\n",
    "    net.add(Dropout(0.5))\n",
    "    net.add(Dense(64, activation='relu'))\n",
    "    net.add(Dropout(0.5))\n",
    "    net.add(Dense(10, activation='softmax'))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = create_model()\n",
    "net.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 3s 5ms/step - loss: 3.0943 - accuracy: 0.1045 - val_loss: 2.2959 - val_accuracy: 0.1610\n",
      "Epoch 2/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 2.3281 - accuracy: 0.1430 - val_loss: 2.0713 - val_accuracy: 0.2590\n",
      "Epoch 3/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 2.0715 - accuracy: 0.1935 - val_loss: 1.7582 - val_accuracy: 0.2510\n",
      "Epoch 4/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.8371 - accuracy: 0.2463 - val_loss: 1.5942 - val_accuracy: 0.3430\n",
      "Epoch 5/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.6775 - accuracy: 0.3015 - val_loss: 1.3613 - val_accuracy: 0.4770\n",
      "Epoch 6/60\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.4881 - accuracy: 0.3873 - val_loss: 0.9543 - val_accuracy: 0.7530\n",
      "Epoch 7/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.3073 - accuracy: 0.4785 - val_loss: 0.8785 - val_accuracy: 0.7420\n",
      "Epoch 8/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.1411 - accuracy: 0.5390 - val_loss: 0.7341 - val_accuracy: 0.6990\n",
      "Epoch 9/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0227 - accuracy: 0.6060 - val_loss: 0.6246 - val_accuracy: 0.7880\n",
      "Epoch 10/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9827 - accuracy: 0.6250 - val_loss: 0.5966 - val_accuracy: 0.8140\n",
      "Epoch 11/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8835 - accuracy: 0.6793 - val_loss: 0.5393 - val_accuracy: 0.8290\n",
      "Epoch 12/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7934 - accuracy: 0.7075 - val_loss: 0.5127 - val_accuracy: 0.8380\n",
      "Epoch 13/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7983 - accuracy: 0.7150 - val_loss: 0.4951 - val_accuracy: 0.8370\n",
      "Epoch 14/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7897 - accuracy: 0.7278 - val_loss: 0.5382 - val_accuracy: 0.8340\n",
      "Epoch 15/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7036 - accuracy: 0.7502 - val_loss: 0.5085 - val_accuracy: 0.8490\n",
      "Epoch 16/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6984 - accuracy: 0.7570 - val_loss: 0.4481 - val_accuracy: 0.8430\n",
      "Epoch 17/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6295 - accuracy: 0.7862 - val_loss: 0.4880 - val_accuracy: 0.8850\n",
      "Epoch 18/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5832 - accuracy: 0.8167 - val_loss: 0.5401 - val_accuracy: 0.9120\n",
      "Epoch 19/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6138 - accuracy: 0.8195 - val_loss: 0.5264 - val_accuracy: 0.9100\n",
      "Epoch 20/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5913 - accuracy: 0.8173 - val_loss: 0.5032 - val_accuracy: 0.9060\n",
      "Epoch 21/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5391 - accuracy: 0.8378 - val_loss: 0.5371 - val_accuracy: 0.9210\n",
      "Epoch 22/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5126 - accuracy: 0.8537 - val_loss: 0.4793 - val_accuracy: 0.9050\n",
      "Epoch 23/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5550 - accuracy: 0.8535 - val_loss: 0.5826 - val_accuracy: 0.9070\n",
      "Epoch 24/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5068 - accuracy: 0.8512 - val_loss: 0.4947 - val_accuracy: 0.9080\n",
      "Epoch 25/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5390 - accuracy: 0.8645 - val_loss: 0.4613 - val_accuracy: 0.9160\n",
      "Epoch 26/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5386 - accuracy: 0.8600 - val_loss: 0.5011 - val_accuracy: 0.9250\n",
      "Epoch 27/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5504 - accuracy: 0.8680 - val_loss: 0.4524 - val_accuracy: 0.9270\n",
      "Epoch 28/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5169 - accuracy: 0.8627 - val_loss: 0.4405 - val_accuracy: 0.9270\n",
      "Epoch 29/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5369 - accuracy: 0.8752 - val_loss: 0.4247 - val_accuracy: 0.9330\n",
      "Epoch 30/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4921 - accuracy: 0.8710 - val_loss: 0.4503 - val_accuracy: 0.9320\n",
      "Epoch 31/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4419 - accuracy: 0.8827 - val_loss: 0.4124 - val_accuracy: 0.9330\n",
      "Epoch 32/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4456 - accuracy: 0.8903 - val_loss: 0.5399 - val_accuracy: 0.9370\n",
      "Epoch 33/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4933 - accuracy: 0.8878 - val_loss: 0.4475 - val_accuracy: 0.9400\n",
      "Epoch 34/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5347 - accuracy: 0.8737 - val_loss: 0.4117 - val_accuracy: 0.9290\n",
      "Epoch 35/60\n",
      " 76/250 [========>.....................] - ETA: 0s - loss: 0.4413 - accuracy: 0.8849"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:139\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_handler\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 139\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_traceback_filtering_enabled():\n\u001b[1;32m    141\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.fit(x_train, y_train, epochs=60, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save('classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinic_transform(x):\n",
    "    #22_proba1.pnz\n",
    "    #BEST ONE\n",
    "    array_size = x.shape\n",
    "    mul = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    add = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    matrix_mult = np.tile(mul,(array_size[0],1))\n",
    "    matrix_add = np.tile(add,(array_size[0],1))\n",
    "    return np.multiply(x,matrix_mult)+matrix_add,mul,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinic_transform2(x):\n",
    "    #24_proba2.pnz\n",
    "    array_size = x.shape\n",
    "    mul = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    add = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    matrix_mult = np.tile(mul,(array_size[0],1))\n",
    "    matrix_add = np.tile(add,(array_size[0],1))\n",
    "    result = np.multiply(x,matrix_mult)+matrix_add\n",
    "    padding = np.zeros((result.shape[0],32))\n",
    "    print(result.shape)\n",
    "    result = np.hstack([padding,result])\n",
    "    print(result.shape)\n",
    "    column_indices = np.random.permutation(result.shape[1])\n",
    "\n",
    "    return result[:,column_indices],mul,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinic_transform3(x):\n",
    "    #01_proba3.pnz\n",
    "    array_size = x.shape\n",
    "    mul = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    add = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    matrix_mult = np.tile(mul,(array_size[0],1))\n",
    "    matrix_add = np.tile(add,(array_size[0],1))\n",
    "    result = np.multiply(x,matrix_mult)+matrix_add\n",
    "    padding = np.zeros((result.shape[0],32))\n",
    "    print(result.shape)\n",
    "    result = np.hstack([padding,result])\n",
    "    print(result.shape)\n",
    "    column_indices = np.random.permutation(result.shape[1])\n",
    "\n",
    "    return result[:,column_indices],mul,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinic_transform4(x):\n",
    "    #10_proba4.pnz\n",
    "    array_size = x.shape\n",
    "    mul = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    add = np.random.uniform(-20,20,size=(1,x.shape[1]))\n",
    "    matrix_mult = np.tile(mul,(array_size[0],1))\n",
    "    matrix_add = np.tile(add,(array_size[0],1))\n",
    "    result = np.multiply(x,matrix_mult)+matrix_add\n",
    "    random = np.random.uniform(-2,2,size=((result.shape[0],64)))\n",
    "    result = np.hstack([random,result])\n",
    "    column_indices = np.random.permutation(result.shape[1])\n",
    "\n",
    "    return result[:,column_indices],mul,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinic_transform5(x):\n",
    "    #11_proba5.pnz\n",
    "    array_size = x.shape\n",
    "    mul = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    add = np.random.uniform(-2,2,size=(1,x.shape[1]))\n",
    "    matrix_mult = np.tile(mul,(array_size[0],1))\n",
    "    matrix_add = np.tile(add,(array_size[0],1))\n",
    "    result = np.multiply(x,matrix_mult)+matrix_add\n",
    "    random = np.random.uniform(-3,3,size=((result.shape[0],64)))\n",
    "    result = np.hstack([random,result])\n",
    "    column_indices = np.random.permutation(result.shape[1])\n",
    "\n",
    "    return result[:,column_indices],mul,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinic_transform6(x):\n",
    "    #11_proba6.pnz\n",
    "    array_size = x.shape\n",
    "    mul = np.random.uniform(-1,1,size=(1,x.shape[1]))\n",
    "    add = np.random.uniform(-2,2,size=(1,x.shape[1]))\n",
    "    matrix_mult = np.tile(mul,(array_size[0],1))\n",
    "    matrix_add = np.tile(add,(array_size[0],1))\n",
    "    result = np.multiply(x,matrix_mult)+matrix_add\n",
    "    random = np.random.uniform(-3,3,size=((result.shape[0],128)))\n",
    "    result = np.hstack([random,result])\n",
    "    column_indices = np.random.permutation(result.shape[1])\n",
    "\n",
    "    return result[:,column_indices],mul,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transform, mul, add = affinic_transform6(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_aff = create_model()\n",
    "\n",
    "net_aff.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "250/250 [==============================] - 3s 5ms/step - loss: 2.8358 - accuracy: 0.1037 - val_loss: 2.3044 - val_accuracy: 0.0980\n",
      "Epoch 2/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 2.3490 - accuracy: 0.1055 - val_loss: 2.3048 - val_accuracy: 0.0980\n",
      "Epoch 3/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 2.3275 - accuracy: 0.0978 - val_loss: 2.3048 - val_accuracy: 0.0980\n",
      "Epoch 4/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 2.3039 - accuracy: 0.1055 - val_loss: 2.2070 - val_accuracy: 0.1850\n",
      "Epoch 5/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 2.1502 - accuracy: 0.1737 - val_loss: 2.0217 - val_accuracy: 0.1800\n",
      "Epoch 6/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 2.0423 - accuracy: 0.1943 - val_loss: 1.9566 - val_accuracy: 0.1820\n",
      "Epoch 7/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.9993 - accuracy: 0.1980 - val_loss: 1.9508 - val_accuracy: 0.2120\n",
      "Epoch 8/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.9483 - accuracy: 0.2243 - val_loss: 1.6196 - val_accuracy: 0.2960\n",
      "Epoch 9/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.7773 - accuracy: 0.2860 - val_loss: 1.4614 - val_accuracy: 0.4590\n",
      "Epoch 10/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.6474 - accuracy: 0.3365 - val_loss: 1.3915 - val_accuracy: 0.4700\n",
      "Epoch 11/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.5433 - accuracy: 0.3523 - val_loss: 1.3089 - val_accuracy: 0.4980\n",
      "Epoch 12/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.4444 - accuracy: 0.3963 - val_loss: 1.2300 - val_accuracy: 0.5150\n",
      "Epoch 13/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.3997 - accuracy: 0.4145 - val_loss: 1.1968 - val_accuracy: 0.5490\n",
      "Epoch 14/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.3448 - accuracy: 0.4353 - val_loss: 1.1258 - val_accuracy: 0.6200\n",
      "Epoch 15/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.3092 - accuracy: 0.4518 - val_loss: 1.1260 - val_accuracy: 0.5360\n",
      "Epoch 16/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.2673 - accuracy: 0.4720 - val_loss: 1.1112 - val_accuracy: 0.5830\n",
      "Epoch 17/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.2244 - accuracy: 0.4837 - val_loss: 0.9997 - val_accuracy: 0.5910\n",
      "Epoch 18/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.2094 - accuracy: 0.4870 - val_loss: 0.9647 - val_accuracy: 0.6380\n",
      "Epoch 19/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.1797 - accuracy: 0.5100 - val_loss: 0.9711 - val_accuracy: 0.6180\n",
      "Epoch 20/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.1644 - accuracy: 0.5153 - val_loss: 0.9078 - val_accuracy: 0.6330\n",
      "Epoch 21/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.1484 - accuracy: 0.5288 - val_loss: 0.9535 - val_accuracy: 0.5640\n",
      "Epoch 22/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.1216 - accuracy: 0.5282 - val_loss: 0.9262 - val_accuracy: 0.5980\n",
      "Epoch 23/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.1063 - accuracy: 0.5420 - val_loss: 0.9331 - val_accuracy: 0.5760\n",
      "Epoch 24/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0756 - accuracy: 0.5452 - val_loss: 0.9681 - val_accuracy: 0.6170\n",
      "Epoch 25/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.1026 - accuracy: 0.5518 - val_loss: 0.9448 - val_accuracy: 0.6350\n",
      "Epoch 26/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.1095 - accuracy: 0.5408 - val_loss: 0.8825 - val_accuracy: 0.6460\n",
      "Epoch 27/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0327 - accuracy: 0.5667 - val_loss: 0.8917 - val_accuracy: 0.6120\n",
      "Epoch 28/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0663 - accuracy: 0.5673 - val_loss: 0.8704 - val_accuracy: 0.6160\n",
      "Epoch 29/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0378 - accuracy: 0.5567 - val_loss: 0.9047 - val_accuracy: 0.5840\n",
      "Epoch 30/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0965 - accuracy: 0.5755 - val_loss: 0.8556 - val_accuracy: 0.6350\n",
      "Epoch 31/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9992 - accuracy: 0.5803 - val_loss: 0.9438 - val_accuracy: 0.6230\n",
      "Epoch 32/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9987 - accuracy: 0.5770 - val_loss: 0.9216 - val_accuracy: 0.6240\n",
      "Epoch 33/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0453 - accuracy: 0.5835 - val_loss: 0.9115 - val_accuracy: 0.6110\n",
      "Epoch 34/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0072 - accuracy: 0.5847 - val_loss: 0.8781 - val_accuracy: 0.6240\n",
      "Epoch 35/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9746 - accuracy: 0.5870 - val_loss: 0.9632 - val_accuracy: 0.6270\n",
      "Epoch 36/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9302 - accuracy: 0.5943 - val_loss: 0.9195 - val_accuracy: 0.6420\n",
      "Epoch 37/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9287 - accuracy: 0.6058 - val_loss: 0.8725 - val_accuracy: 0.6380\n",
      "Epoch 38/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9401 - accuracy: 0.6035 - val_loss: 0.8687 - val_accuracy: 0.6370\n",
      "Epoch 39/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0054 - accuracy: 0.5957 - val_loss: 0.8924 - val_accuracy: 0.6250\n",
      "Epoch 40/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0167 - accuracy: 0.6030 - val_loss: 0.8689 - val_accuracy: 0.6350\n",
      "Epoch 41/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0208 - accuracy: 0.5847 - val_loss: 0.8330 - val_accuracy: 0.6600\n",
      "Epoch 42/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0277 - accuracy: 0.5910 - val_loss: 0.8624 - val_accuracy: 0.6420\n",
      "Epoch 43/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0350 - accuracy: 0.6033 - val_loss: 0.9058 - val_accuracy: 0.6230\n",
      "Epoch 44/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9452 - accuracy: 0.5978 - val_loss: 0.8440 - val_accuracy: 0.6360\n",
      "Epoch 45/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9497 - accuracy: 0.6065 - val_loss: 0.8251 - val_accuracy: 0.6640\n",
      "Epoch 46/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8903 - accuracy: 0.6220 - val_loss: 0.9069 - val_accuracy: 0.6310\n",
      "Epoch 47/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8761 - accuracy: 0.6215 - val_loss: 0.9109 - val_accuracy: 0.6500\n",
      "Epoch 48/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8866 - accuracy: 0.6227 - val_loss: 0.9263 - val_accuracy: 0.6530\n",
      "Epoch 49/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8527 - accuracy: 0.6223 - val_loss: 0.8890 - val_accuracy: 0.6660\n",
      "Epoch 50/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8578 - accuracy: 0.6210 - val_loss: 0.8708 - val_accuracy: 0.6490\n",
      "Epoch 51/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9114 - accuracy: 0.6148 - val_loss: 0.8688 - val_accuracy: 0.6520\n",
      "Epoch 52/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8824 - accuracy: 0.6208 - val_loss: 0.8204 - val_accuracy: 0.6490\n",
      "Epoch 53/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8808 - accuracy: 0.6240 - val_loss: 0.8639 - val_accuracy: 0.6510\n",
      "Epoch 54/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9238 - accuracy: 0.6245 - val_loss: 0.9398 - val_accuracy: 0.6420\n",
      "Epoch 55/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8638 - accuracy: 0.6242 - val_loss: 0.9465 - val_accuracy: 0.6500\n",
      "Epoch 56/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8593 - accuracy: 0.6273 - val_loss: 0.8725 - val_accuracy: 0.6700\n",
      "Epoch 57/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8831 - accuracy: 0.6205 - val_loss: 0.9493 - val_accuracy: 0.6470\n",
      "Epoch 58/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.9324 - accuracy: 0.6267 - val_loss: 1.0332 - val_accuracy: 0.6380\n",
      "Epoch 59/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8580 - accuracy: 0.6295 - val_loss: 0.9634 - val_accuracy: 0.6590\n",
      "Epoch 60/60\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.8736 - accuracy: 0.6227 - val_loss: 0.9982 - val_accuracy: 0.6510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5ea7c0bb0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_aff.fit(x_transform, y_train, epochs=60, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load(\"/home/mati/AGH/AIHack/DefenseTransformationSubmit.npz\")\n",
    "X_EVAL=X['representations']\n",
    "X_EVAL,_,_ = affinic_transform5(X_EVAL)\n",
    "X_EVAL = X_EVAL.astype('float32')\n",
    "np.savez(\"11_proba6.npz\",representations=X_EVAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['representations']\n",
      "(20250, 256)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "b=np.load(\"thunder_sparrows.npz\",allow_pickle=True)\n",
    "X_EVAL=b['representations']\n",
    "print(b.files)\n",
    "print(X_EVAL.shape)\n",
    "print(X_EVAL[0].dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
